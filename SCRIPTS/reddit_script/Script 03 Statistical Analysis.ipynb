{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c4777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#statistical testing libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21c01e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data: output/shipping_comments_clean.csv\n",
      "Saving tables to: output/tables\n"
     ]
    }
   ],
   "source": [
    "# Paths (must match Script 01 output structure)\n",
    "OUTDIR = \"output\"\n",
    "DATA_PATH = os.path.join(OUTDIR, \"shipping_comments_clean.csv\")\n",
    "# Statistical testing libraries\n",
    "TAB_DIR = os.path.join(OUTDIR, \"tables\")\n",
    "os.makedirs(TAB_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Using data:\", DATA_PATH)\n",
    "print(\"Saving tables to:\", TAB_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "264eada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (2006, 14)\n",
      "Columns: ['company', 'subreddit', 'post_id', 'comment_id', 'comment_created_utc', 'comment_body', 'comment_score', 'parent_id', 'comment_created_dt', 'text_raw', 'text_clean', 'keep_basic', 'is_boilerplate', 'keep_final']\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "# Ensure required columns exist\n",
    "required_cols = [\"company\", \"text_clean\"]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns from Script 01: {missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf0dd25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER not found → computing sentiment scores...\n"
     ]
    }
   ],
   "source": [
    "# Compute VADER\n",
    "# VADER compound score ranges from -1 to +1\n",
    "#   >= 0.05  → Positive\n",
    "#   <= -0.05 → Negative\n",
    "#   otherwise → Neutral\n",
    "\n",
    "if \"vader_compound\" not in df.columns:\n",
    "    print(\"VADER not found → computing sentiment scores...\")\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    # Apply VADER to each cleaned comment\n",
    "    scores = df[\"text_clean\"].astype(str).apply(analyzer.polarity_scores)\n",
    "    scores_df = pd.DataFrame(list(scores))\n",
    "    \n",
    "    # Rename to our consistent naming convention\n",
    "    scores_df = scores_df.rename(columns={\n",
    "        \"compound\": \"vader_compound\",\n",
    "        \"pos\": \"vader_pos\",\n",
    "        \"neu\": \"vader_neu\",\n",
    "        \"neg\": \"vader_neg\"\n",
    "    })\n",
    "    # Merge back into main dataframe\n",
    "    df = pd.concat([df.reset_index(drop=True),\n",
    "                    scores_df.reset_index(drop=True)], axis=1)\n",
    "else:\n",
    "    print(\"Using existing VADER columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaba9ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ONE-WAY ANOVA ===\n",
      "Levene test p-value: 0.05439216397522384\n",
      "F-statistic: 10.413373896754942\n",
      "p-value: 8.473258852253513e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== ONE-WAY ANOVA ===\")\n",
    "# Test whether mean sentiment differs by company\n",
    "# H0: All company means are equal\n",
    "# H1: At least one company mean differs\n",
    "\n",
    "analysis_df = df[[\"company\", \"vader_compound\"]].dropna()\n",
    "\n",
    "groups = [\n",
    "    analysis_df.loc[analysis_df[\"company\"] == c, \"vader_compound\"].values\n",
    "    for c in analysis_df[\"company\"].unique()\n",
    "]\n",
    "\n",
    "# Assumption check, equal variances\n",
    "# Levene test:\n",
    "# H0: Variances are equal across groups\n",
    "lev_stat, lev_p = stats.levene(*groups)\n",
    "print(\"Levene test p-value:\", lev_p)\n",
    "\n",
    "# ANOVA\n",
    "f_stat, p_anova = stats.f_oneway(*groups)\n",
    "\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_anova)\n",
    "# Save results\n",
    "anova_results = pd.DataFrame({\n",
    "    \"F_statistic\": [f_stat],\n",
    "    \"p_value\": [p_anova],\n",
    "    \"levene_p_value\": [lev_p]\n",
    "})\n",
    "\n",
    "anova_results.to_csv(os.path.join(TAB_DIR, \"anova_results.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a0b48f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TUKEY HSD (Post-hoc) ===\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "   DHL  FedEx  -0.1549  0.001 -0.2521 -0.0578   True\n",
      "   DHL    UPS  -0.0274  0.899   -0.13  0.0751  False\n",
      "   DHL   USPS  -0.0389 0.6875 -0.1329  0.0551  False\n",
      " FedEx    UPS   0.1275  0.001  0.0506  0.2044   True\n",
      " FedEx   USPS    0.116  0.001   0.051   0.181   True\n",
      "   UPS   USPS  -0.0115    0.9 -0.0844  0.0614  False\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TUKEY HSD (Post-hoc) ===\")\n",
    "\n",
    "# Used only if ANOVA is significant\n",
    "# Compares every pair of companies\n",
    "# Controls family-wise error rate (FWER)\n",
    "\n",
    "try:\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "    \n",
    "    tukey = pairwise_tukeyhsd(\n",
    "        endog=analysis_df[\"vader_compound\"],\n",
    "        groups=analysis_df[\"company\"],\n",
    "        alpha=0.05\n",
    "    )\n",
    "    \n",
    "    print(tukey)\n",
    "    \n",
    "    tukey_df = pd.DataFrame(\n",
    "        data=tukey.summary().data[1:], \n",
    "        columns=tukey.summary().data[0]\n",
    "    )\n",
    "    \n",
    "    tukey_df.to_csv(os.path.join(TAB_DIR, \"tukey_results.csv\"), index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Tukey skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96fa8807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BINOMIAL TEST (>50% Negative) ===\n",
      "  company    n  negative_count  negative_proportion  p_value\n",
      "0     DHL  205              52             0.253659      1.0\n",
      "1   FedEx  597             223             0.373534      1.0\n",
      "2     UPS  411             115             0.279805      1.0\n",
      "3    USPS  793             232             0.292560      1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== BINOMIAL TEST (>50% Negative) ===\")\n",
    "\n",
    "# Test whether MORE than 50% of comments are negative\n",
    "#\n",
    "# H0: p_negative = 0.5\n",
    "# H1: p_negative > 0.5\n",
    "\n",
    "# Convert compound score into categorical sentiment\n",
    "df[\"sentiment_label\"] = df[\"vader_compound\"].apply(\n",
    "    lambda x: \"Positive\" if x >= 0.05 else\n",
    "              \"Negative\" if x <= -0.05 else\n",
    "              \"Neutral\"\n",
    ")\n",
    "# Binary indicator: 1 if negative\n",
    "df[\"neg_binary\"] = (df[\"sentiment_label\"] == \"Negative\").astype(int)\n",
    "\n",
    "#1 sided binomial test\n",
    "def binom_pvalue_greater(k, n, p0=0.5):\n",
    "    try:\n",
    "        from scipy.stats import binomtest\n",
    "        return binomtest(k, n, p=p0, alternative=\"greater\").pvalue\n",
    "    except:\n",
    "        from scipy.stats import binom_test\n",
    "        return binom_test(k, n, p=p0, alternative=\"greater\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for company, sub in df.groupby(\"company\"):\n",
    "    n = len(sub)\n",
    "    k = sub[\"neg_binary\"].sum()\n",
    "    pval = binom_pvalue_greater(k, n)\n",
    "    \n",
    "    results.append({\n",
    "        \"company\": company,\n",
    "        \"n\": n,\n",
    "        \"negative_count\": k,\n",
    "        \"negative_proportion\": k / n,\n",
    "        \"p_value\": pval\n",
    "    })\n",
    "\n",
    "binom_df = pd.DataFrame(results)\n",
    "print(binom_df)\n",
    "\n",
    "binom_df.to_csv(os.path.join(TAB_DIR, \"binomial_results.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b79bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHI-SQUARE TEST ===\n",
      "Chi-square statistic: 18.217001716688817\n",
      "p-value: 0.005712173619927964\n",
      "Degrees of freedom: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== CHI-SQUARE TEST ===\")\n",
    "\n",
    "# Test whether sentiment distribution differs by company\n",
    "#\n",
    "# H0: Sentiment and company are independent\n",
    "# H1: They are associated\n",
    "\n",
    "cont_table = pd.crosstab(df[\"company\"], df[\"sentiment_label\"])\n",
    "\n",
    "# Run chi-square test\n",
    "chi2, p_chi2, dof, expected = chi2_contingency(cont_table)\n",
    "\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p_chi2)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "\n",
    "# Effect size (Cramer's V)\n",
    "n_total = cont_table.values.sum()\n",
    "r, c = cont_table.shape\n",
    "cramers_v = np.sqrt(chi2 / (n_total * (min(r - 1, c - 1))))\n",
    "\n",
    "chi_results = pd.DataFrame({\n",
    "    \"chi2\": [chi2],\n",
    "    \"p_value\": [p_chi2],\n",
    "    \"degrees_freedom\": [dof],\n",
    "    \"cramers_v\": [cramers_v]\n",
    "})\n",
    "\n",
    "chi_results.to_csv(os.path.join(TAB_DIR, \"chi_square_results.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b659ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
